---
layout: default
title: Research and Projects
---

	<h1>{{ page.title }}</h1>
	<p><br></p>

	<h1>Publications</h1>
	<ul>
	<li><a href="https://arxiv.org/abs/1909.06718">LRS-DAG: Low Resource Supervised Domain Adaptation with Generalization Across Domains.</a>[<a href="https://www.youtube.com/watch?v=17nxep0Ux50&feature=youtu.be">Talk</a>]<br><small><i><b>Rheeya Uppaal</b></i><br>In the New in ML Workshop of the Thirty-third Conference on Neural Information Processing Systems (<b>NeurIPS 2019</b>).</small></li>
	<li><a href="http://roseyu.com/time-series-workshop/submissions/2019/timeseries-ICML19_paper_55.pdf">Multi-resolution Attention with Signal Splitting for Multivariate Time Series Classification.</a><br><small><i><b>Rheeya Uppaal</b>, Bryon Kucharski, Bhanu Pratap Singh, Iman Deznabi, Madelina Fiterau.</i><br>Time Series Workshop of The Thirty-sixth International Conference on Machine Learning (<b>ICML 2019</b>).</small></li>
	<li><a href="https://arxiv.org/abs/1911.07335">Overcoming Practical Issues of Deep Active Learning and its Applications on Named Entity Recognition.</a><br><small><i>Haw-Shiuan Chang, Shankar Vembu, Sunil Mohan, <b>Rheeya Uppaal</b>, Andrew McCallum.</i><br>In the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (<b>ECML-PKDD 2020</b>) (Journal Track)</small></li>
	<li><a href="https://arxiv.org/abs/1905.00125">Multi-resolution Networks For Flexible Irregular Time Series Modeling (Multi-FIT)</a><br><small><i>Bhanu Pratap Singh, Iman Deznabi, <b>Rheeya Uppaal</b>, Bryon Kucharski, Bharath Narasimhan, Akhila Josyula, Madelina Fiterau.</i><br>Unpublished.</small></li>
	<li><a href="https://drive.google.com/file/d/19u5PwBdRXN6555aIIx0LgTeysS_bwTT5/view">Combating Unbalanced Datasets with Generative Adversarial Networks</a><br><small><i><b>Rheeya Uppaal</b></i>.<br>Presented at the Women in Data Science Central Massachusetts Conference (WiDS 2018).</small></li>
	<li><a href="https://ijrat.org/downloads/Conference_Proceedings/ncpci2016/ncpci-02.pdf">Exploring Robust Vehicle Detection and Tracking Methods for Various Illumination Settings using Infrared Thermographic Images</a><br><small><b><i>Rheeya Uppaal</i></b>.<br>In the International Journal of Research in Advent Technology, Special Issue National Conference NCPC, 2016.</small></li>	
	<li> <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3306567">Leveraging One's Impact Through Digital Persona and Image Management for Enhanced Effectiveness and Competitive Advantage</a>.<br><small><i>Kuiljeit Uppaal, <b>Rheeya Uppaal</b></i><br>Elsevier, 2018.</small></li>
	<li> <a href="https://drive.google.com/file/d/1Upq_uYb5GyOm8xf69k1Ca37ycIyI1b-z/view?usp=sharing"> Exploring the Facets of Colonization of the Red Planet â€“ Mars.</a><br><small><i><b>Rheeya Uppaal</b></i><br>In the Conference on Emerging Technologies and Innovations, 2014.</small></li>		
	</ul>

	<h1>Projects</h1>

	<h2>Low Resource Supervised Domain Adaptation with Generalization Across Domains</h2>
	<p><a href="https://arxiv.org/abs/1909.06718">PDF</a> | <a href="https://github.com/Uppaal/LRS-DAG">Code</a> | <a href="https://youtu.be/17nxep0Ux50">Talk</a>
	<p align="justify">Current state of the art methods in Domain Adaptation follow adversarial approaches, making training a challenge. Other non-adversarial methods learn mappings between source and target domains, to achieve reasonable performance. However, even these methods do not focus a key aspect of maintaining performance on the source domain, even after optimizing over the target domain. Additionally, there exist very few methods in low resource supervised domain adaptation. This work proposes a method, LRS-DAG, that aims to solve these current issues in the field. By adding a set of "encoder layers" which map the target domain to the source, and can be removed when dealing directly with the source data, the model learns to perform optimally on both domains. LRS-DAG is unique in the sense that a new algorithm for low resource domain adaptation, which maintains performance over the source, with a new metric for learning mappings has been introduced.</p>
	<br>

	<h2>Transfer Learning for Question to Answer Ranking Problems in New Domains</h2>
	<p><a href="https://drive.google.com/file/d/1Qq6WlCYa9Zaws5OHORRjNV96LyY8I8k5/view?usp=sharing">PDF</a> | <a href="https://github.com/Uppaal/bi-att-flow">Code</a>
	<p align="justify">Recent advances in deep learning techniques for machine reading comprehension and question answering have dramatically improved the performance of question answering technology on open-ended questions. These techniques answer questions by identifying snippets or sections of text from a larger document (or document collection) where the extracted text contains an explicit answer to the question posed.  While building a general purpose question answering model is an excellent long-term goal, there are many real world scenarios in which building a domain-dependent model is sufficient. However, there is often only a limited amount of in-domain data to train from in each new domain. In this scenario, it may be possible to apply transfer learning to adapt either a general purpose model, or a domain-dependent model from a similar domain, to produce an effective model for the new domain.</p>
 	<p align="justify">The field of Transfer Learning deals with adapting a model, trained on a particular task or domain, to perform on a new task or domain. This work focuses on transferring knowledge across domains, labelling the target domain data is often expensive and causes a scarcity in labelled data. In particular, the task of closed-domain Reaching Comprehension has been considered, by training the model on the Stanford Question Answering Dataset (SQuAD), and transferring this knowledge to the NewsQA Dataset. We explored the method of Joint Training and Active Learning which emulate the real world scenario of having a small amount of data in the target domain to be learnt, and a large quantity of data from the source domain. We also explored Adversarial Methods to learn domain specific and domain invariant features, optimizing for a minimax loss function.</p>
	<br>

	<h2>One Shot Learning: Exploring Matching Networks</h2>
	<p><a href="https://drive.google.com/file/d/1M04JMfKoYB1JFYjEO9xlqwTbKIerZq4k/view?usp=sharing">PDF</a> | <a href="https://github.com/Uppaal/Matching_Networks_with_STN">Code</a></p>
	<p align="justify">Data is a highly important factor in Deep Learning. The presence of a large, labeled and balanced dataset is often essential for a model to perform optimally at a particular task. However, finding such data in the real world is rare, and creating these datasets is a tedious task. One-Shot learning is a new field which aims to solve this problem, by enabling a model to learn from a single example per class. This project explores Matching Networks, a high performing One-Shot learning architecture. The importance of certain features of Matching Networks have been analyzed through an ablation study. Additionally, a Spacial Transformer Network has been introduced into the encoding function, to make the model robust to rotational invariance. Finally, a new few shot learning dataset on Pokemon was created, but could not be used to train the model due to computational expensiveness.</p>
	<br>
 
	<h2>Combating Unbalanced Datasets with Generative Adversarial Networks</h2>
	<p><a href="https://drive.google.com/file/d/19u5PwBdRXN6555aIIx0LgTeysS_bwTT5/view?usp=sharing">PDF</a> | <a href="https://github.com/Uppaal/GANs_for_data_augmentation">Code</a></p>
	<p align="justify">Data is a highly important factor in Deep Learning. The presence of a large, labeled and balanced dataset is often essential for a model to perform optimally at a particular task. However, finding such data in the real world is rare, and creating these datasets is a tedious task.</p>
	<p align="justify">The aim of this project is to overcome one of the aspects of difficulties with datasets: unbalanced data across different classes. In more detail, Generative Adversarial Networks (GANs) have been used on an existing unbalanced dataset to create synthetic data of
the lesser represented classes. To my best knowledge, GANs have never been used for this purpose before. </p>
	<p align="justify"> Using Deep Convolutional GANs after pretraining the Discriminator on the dataset gave promising results which surpassed the baseline method and almost matched the original dataset.</p>
	<br>

	<h2>Character Identification in Multi-party Dialogue settings using Convolutional Neural Networks</h2>
	<p><a href="https://drive.google.com/file/d/1lNwmw11_yHtDL3asdmdHZ2N5xtAzo5ZB/view?usp=sharing">PDF</a> | <a href="https://github.com/Uppaal/multiparty_dialogues_entity_linking">Code</a></p>
	<p align="justify">Character Identification an entity linking task, where each Mention, or a nominal referring to a person, is mapped to its respective Entity, or character of the dialogue. Our work evaluates the current state of the art method of Character Identification in a multiparty setting. The architecture of this methodology uses the Agglomerative-CNN which creates clusters of mentions using their embeddings and features related to information about the context, gender and plurality of mentions. These unlabelled clusters are linked to their respective entities using a simple feed forward architecture. Using word and sentence embeddings generated by transferring knowledge from a separately trained neural model boosted the performance of the model by almost two percent. While our model does not equal the model paper percentage, we found this method to create a significant improvement over our implementation of the model paper.</p>
	<br>

	<h2>Using Region based Convolutional Neural Networks to create a system to detect, track and classify vehicles from video footage.</h2>
	<p><a href="https://github.com/Uppaal/Projects/blob/master/Vehicles/Project%20Report%20(with%20Implementation%20Details).pdf">PDF</a> | <a href="http://rise.cse.iitm.ac.in/rise1/projects/projects.html#ML">Project Page</a></p>
	<p align="justify">Rich real-time traffic data is being obtained using advanced sensors such as Video and GPS as well as communication technologies at a data centre in the Intelligent Transportation Systems laboratory. This data offers tremendous scope to investigate empirical patterns. The focus of this work is to mine this data to derive empirical understanding and develop models towards this broad goal. Specific focus areas include: quantification of the ITS data to investigate the role of various sources that affect system performance (demand, incidents, weather, construction, special events, control devices etc.) and applying this knowledge towards the development of algorithms for optimizing and improving system performance. The project aims to utilize, use deep learning techniques to detect, track and classify vehicles, in real-time, into numerous categories from the video footage of the roads, thus utilizing the traffic data to identify and gauge the levels of traffic at intersections and roads throughout the city of Chennai.</p>
	<p align="justify">As an alternative method of creating a system robust to occlusion and varying illumination changes, I proposed the idea of using infrared radiation to track and published my proposed method on <a href="http://www.ijrat.org/downloads/ncpci2016/ncpci-02.pdf">Exploring Robust Vehicle Detection and Tracking Methods for Various Illumination Settings using Infrared Thermographic Images</a>.
	<br><br>

	<h2>Facial Recognition using Convolutional Neural Networks</h2>
	<p><a href="https://github.com/Uppaal/Projects/blob/master/FER/Project%20Report.pdf">PDF</a></p>
	<p align="justify">Created a Facial Expression Recognition system using vanilla Convolutional Neural Networks, for automatically identifying the condition of patients in hospitals. The model was aimed to be computationally inexpensive, to enable real time tracking through video.</p>
	<br>
